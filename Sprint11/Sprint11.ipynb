{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[課題のURL](https://diver.diveintocode.jp/curriculums/1877)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ 畳み込みニューラルネットワーク1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* データセットをダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "#print(X_train[0].dtype) # uint8\n",
    "#print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 平滑化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape(-1, 784)\n",
    "# X_test = X_test.reshape(-1, 784)\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像は0から255のuint8型で表されますが、機械学習をする上では0から1のfloat型で扱うことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0] # 0から1の値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解ラベルは0から9の整数ですが、ニューラルネットワークで多クラス分類を行う際には one-hot表現 に変換します。  \n",
    "scikit-learnのOneHotEncoderを使用したコードが以下です。  \n",
    "このone-hot表現による値はそのラベルである確率を示していることになるため、float型で扱います。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、訓練データ6万枚の内2割を検証データとして分割してください。  \n",
    "訓練データが48000枚、検証データが12000枚となります。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28)\n",
      "(12000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_one_hot[0])\n",
    "print(y_train_one_hot[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1次元の畳み込みニューラルネットワークスクラッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はこれを任意の層数に拡張しやすいものに書き換えていきます。  \n",
    "その上で、活性化関数や初期値、最適化手法について発展的なものを扱えるようにしていきます。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ミニバッチ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークではデータを分割して入力する 確率的勾配降下法 が一般的です。  \n",
    "分割した際のひとかたまりを ミニバッチ 、そのサンプル数を バッチサイズ と呼びます。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "#print(len(get_mini_batch)) # 2400\n",
    "#print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ\n",
    "    filter_h : フィルターの高さ\n",
    "    filter_w : フィルターの幅\n",
    "    stride : ストライド\n",
    "    pad : パディング\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2次元配列\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "    filter_h :\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col_slow(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for move_y in range(out_h):\n",
    "        for move_x in range(out_w):\n",
    "            for y in range(filter_h):\n",
    "                for x in range(filter_w):\n",
    "                    col[:, :, y, x, move_y, move_x] = \\\n",
    "                        img[:, :, y + stride * move_y, x + stride * move_x]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    def __init__(self, W, b, stride=1, pad=0, initializer=\"test\", optimizer=\"test\"):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.col = None\n",
    "        \n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def calc_N_out(self, N_in, P, F, S):\n",
    "    \n",
    "        N_out = (N_in + 2*P - F)/S + 1\n",
    "\n",
    "        return int(N_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N_in = x.shape[0] # 入力サイズ\n",
    "        P = self.pad # ある方向へのパディング数\n",
    "        F = self.W.shape[0] # フィルタのサイズ\n",
    "        S = self.stride # ストライドのサイズ\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        N_out = self.calc_N_out(N_in, P, F, S)\n",
    "\n",
    "        # xを計算しやすようにcolに変換\n",
    "        col = np.zeros([w.shape[0], N_out])\n",
    "        for i in range(w.shape[0]):\n",
    "            i_max = i + N_out\n",
    "            col[i, :] = x[i:i_max]\n",
    "\n",
    "        self.col = col # backwardで使用\n",
    "        out = np.dot(col.T, self.W) + self.b\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N_out = dout.shape[0]\n",
    "        n_w = self.W.shape[0]\n",
    "        n_x = self.x.shape[0]\n",
    "        \n",
    "        dw = np.zeros(n_w)\n",
    "        #for s in range(n_w): # Wのサイズ\n",
    "            #for i in range(N_out):\n",
    "                #dw[s] = dw[s] + self.x[i+s]*dout[i] \n",
    "                # print(s,i, self.x[i+s], dout[i], self.x[i+s]*dout[i])\n",
    "\n",
    "        dw = np.dot(self.col, dout)    \n",
    "        db = np.sum(dout, axis=0)\n",
    "\n",
    "#        self = self.optimizer.update(self, dw, db)\n",
    "        \n",
    "        # dx(x)分\n",
    "        dx = np.zeros(n_x)\n",
    "        #for j in range(n_x): # データサイズ\n",
    "            #for s in range(n_w): # Wのサイズ\n",
    "                #if (j-s)>=0 and (j-s)<=(N_out-1):\n",
    "                    #print(j, s, dout[j-s], self.W[s], dout[j-s]*self.W[s])\n",
    "                    #dx[j] = dx[j] + dout[j-s]*self.W[s]\n",
    "\n",
    "        # dxを計算しやすいようにdcolに変換\n",
    "        dcol = np.zeros([w.shape[0], N_out])\n",
    "        for i in range(w.shape[0]):\n",
    "            dcol[i,:] = dout * self.W[i]\n",
    "        \n",
    "        dx = np.zeros(x.shape[0])\n",
    "        for i in range(w.shape[0]):\n",
    "            i_max = i + N_out\n",
    "            dx[i:i_max] = dx[i:i_max] + dcol[i,:]\n",
    "                    \n",
    "        return db, dw, dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】1次元畳み込み後の出力サイズの計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "def calc_N_out(self, N_in, P, F, S):\n",
    "    \n",
    "        N_out = (N_in + 2*P - F)/S + 1\n",
    "\n",
    "        return int(N_out)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】小さな配列での1次元畳み込み層の実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35. 50.]\n",
      "30 [ 50.  80. 110.] [ 30. 110. 170. 140.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "\n",
    "class_test = SimpleConv1d(w, b)\n",
    "out = class_test.forward(x)\n",
    "print(out)\n",
    "\n",
    "delta_a = np.array([10, 20])\n",
    "\n",
    "db, dw, dx = class_test.backward(delta_a)\n",
    "print(db, dw, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 期待結果\n",
    "#delta_b = np.array([30])\n",
    "#delta_w = np.array([50, 80, 110])\n",
    "#delta_x = np.array([30, 110, 170, 140])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "        def __init__(self, w, b, stride=1, pad=0):\n",
    "            self.W = w\n",
    "            self.B = b\n",
    "            self.stride = stride\n",
    "            self.pad = pad\n",
    "\n",
    "            # 中間データ（backward時に使用）\n",
    "            self.x = None   \n",
    "            self.col = None\n",
    "            self.col_W = None\n",
    "\n",
    "            # 重み・バイアスパラメータの勾配\n",
    "            self.dW = None\n",
    "            self.db = None\n",
    "\n",
    "        def _N_out_h(self, H, FH):\n",
    "            # H:入力データの高さ、FH:フィルタの高さ\n",
    "            return (1 + int((H + 2*self.pad - FH) / self.stride))\n",
    "\n",
    "        def _N_out_w(self, W, FW):\n",
    "            # W:入力データの高さ、FW:フィルタの高さ\n",
    "            return (1 + int((W + 2*self.pad - FW) / self.stride))\n",
    "\n",
    "        def forward(self, x):\n",
    "            # xのIFを4次元に変更する\n",
    "            # x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
    "\n",
    "            N, C, H, W = x.shape # N:データ数, C:チャネル数、H:データの高さ、W:データの幅\n",
    "            FN, C, FH, FW = self.W.shape # FN:フィルタ数、C:チャネル数、FH:フィルタの高さ、FW:フィルタの幅\n",
    "            \n",
    "            # 一つあたりの出力データのサイズ(畳み込み後のサイズ)を求める\n",
    "            out_h = self._N_out_h(H, FH)\n",
    "            out_w = self._N_out_w(W, FW)\n",
    "            #print(\"出力データのサイズ\")\n",
    "            #print(out_h, out_w)\n",
    "\n",
    "            # 演算を行うため2次元のデータに変換する\n",
    "            col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "            #print(col)\n",
    "            \n",
    "            col_W = self.W.reshape(FN, -1).T\n",
    "            #print(col_W)\n",
    "            \n",
    "            # 畳み込み処理\n",
    "            out = np.dot(col, col_W) + self.B\n",
    "            #print(out.shape)\n",
    "            #print(out)\n",
    "    \n",
    "            # 畳み込み処理の結果を任意の次元に変換 C:チャンネル1の場合\n",
    "            #out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "            #out = out.transpose(1, 0)\n",
    "            _out = np.zeros((FN, out_w))\n",
    "            for ch in range(FN):\n",
    "                _out[ch] = out[ch][:, 0]\n",
    "            \n",
    "            # backward処理のためにデータ保存\n",
    "            self.x = x\n",
    "            self.col = col\n",
    "            self.col_W = col_W\n",
    "\n",
    "            #print(\"Nanの確認\", np.sum(x), np.sum(col), np.sum(col_W))\n",
    "            \n",
    "            return _out\n",
    "\n",
    "        def backward(self, dout):\n",
    "            FN, C, FH, FW = self.W.shape # FN:フィルタ数、C:チャネル数、FH:フィルタの高さ、FW:フィルタの幅\n",
    "\n",
    "            # C:チャンネル1の場合\n",
    "            dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "            #dout =  out.transpose(1, 0)\n",
    "\n",
    "            self.db = np.sum(dout, axis=0)\n",
    "            self.dW = np.dot(self.col.T, dout)\n",
    "            self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "            dcol = np.dot(dout, self.col_W.T)\n",
    "            dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "            # パラメータを更新\n",
    "            # print(\"self.dW, self.dbの確認:更新前\", np.sum(self.dW), np.sum(self.db))\n",
    "            self = self.optimizer.update(self, self.dW, self.db)\n",
    "            # print(\"self.dW, self.dbの確認:更新後\", np.sum(self.dW), np.sum(self.db))\n",
    "    \n",
    "            return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[16. 22.]\n",
      " [17. 23.]\n",
      " [18. 24.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "\n",
    "x_4d = x.reshape(1, 2, 1, 4) # (データ数、チャンネル、h, w)\n",
    "w_4d = w.reshape(3, 2, 1, 3) # (フィルタ数、チャンネル、h, w)\n",
    "b_4d = b.reshape(3, 1, 1) # (フィルタ数、1, 1)\n",
    "\n",
    "class_test = Conv1d(w_4d, b_4d)\n",
    "out = class_test.forward(x_4d)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 期待結果\n",
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、 平滑化 を行なってください。\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    N層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, epoch = 5, alpha = 0.001, activation='sigmoid', optimizer=\"SGD\", init=\"simple\" ,verbose = True):\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.epoch = epoch\n",
    "        self.batch_size = 20 # バッチサイズ\n",
    "        \n",
    "        self.n_features = 784 # 特徴量の数\n",
    "        self.n_nodes1 = 400 # 1層目のノード数\n",
    "        self.n_nodes2 = 100\n",
    "        self.n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "        \n",
    "        self.init_type = init # 初期化方法\n",
    "        self.activation_type = activation # 活性化関数\n",
    "        self.optimizer_type = optimizer # 最適化方法\n",
    "        \n",
    "        self.sigma = 0.01 # ガウス分布の標準偏差\n",
    "        self.lr = alpha\n",
    "\n",
    "    def _encode_10(self, data):\n",
    "        t = np.zeros((data.size, 10))\n",
    "        for i in range(data.size):\n",
    "            t[i, data[i]] = 1\n",
    "        return t\n",
    "\n",
    "    def _calc_loss(self, y, z):\n",
    "        # エントロピー誤差を求める\n",
    "        # 0割回避のため(z=0を防ぐため)\n",
    "        delta = 1e-7\n",
    "        n = y.shape[0]\n",
    "\n",
    "        l = -1/n*np.sum(y*np.log(z+delta))\n",
    "\n",
    "        return l\n",
    "    \n",
    "    class sigmoid:\n",
    "        def __init__(self):\n",
    "            self.out = None\n",
    "        \n",
    "        def _sigmoid(self, x):\n",
    "            sigmoid_range = 34.538776394910684\n",
    "            x = np.clip(x, -sigmoid_range, sigmoid_range)\n",
    "            return 1.0/(1.0+np.exp(-x))\n",
    "        \n",
    "        def forward(self, x):\n",
    "            y = self._sigmoid(x)\n",
    "            self.out = y\n",
    "            \n",
    "            return y\n",
    "\n",
    "        def backward(self, dz):\n",
    "            dA = dz*(1 - self.out)*(self.out)\n",
    "            \n",
    "            return dA\n",
    "    \n",
    "    class ReLU:\n",
    "        def __init__(self):\n",
    "            self.mask = None\n",
    "\n",
    "        def forward(self, x):\n",
    "            self.mask = (x <= 0)\n",
    "            x_out = x.copy()\n",
    "            x_out[self.mask] = 0\n",
    "\n",
    "            return x_out\n",
    "\n",
    "        def backward(self, x):\n",
    "            x[self.mask] = 0\n",
    "            dx = x\n",
    "\n",
    "            return dx\n",
    "    \n",
    "    class activation_softmax:\n",
    "        def __init__(self):\n",
    "            self.y = None\n",
    "            self.t = None # one-hot\n",
    "            \n",
    "        def _softmax(self, x):\n",
    "            n = x.shape[0]\n",
    "\n",
    "            sigmoid_range = 34.538776394910684\n",
    "            x = np.clip(x, -sigmoid_range, sigmoid_range)\n",
    "            \n",
    "            for i in range(n):\n",
    "                exp_x = np.exp(x[i])\n",
    "                sum_exp_x = np.sum(exp_x)\n",
    "                x[i] = exp_x/sum_exp_x\n",
    "\n",
    "            return x\n",
    "        \n",
    "        def forward(self, x):\n",
    "            self.y = self._softmax(x)\n",
    "            \n",
    "            return self.y\n",
    "\n",
    "        def backward(self, z, t):\n",
    "            d = z - t\n",
    "            \n",
    "            return d\n",
    "    \n",
    "    class SimpleInitializer:\n",
    "        def __init__(self, sigma):\n",
    "            self.sigma = sigma\n",
    "        def W(self, n_nodes1, n_nodes2):\n",
    "            np.random.seed(1)\n",
    "            W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "            return W\n",
    "        \n",
    "        def B(self, n_nodes1, n_nodes2):\n",
    "            # n_nodes2は使用しないが、他の初期化関数とIFを合わせる\n",
    "            np.random.seed(1)\n",
    "            b = self.sigma * np.random.randn(n_nodes2)\n",
    "            return b\n",
    "\n",
    "    class XavierInitializer:\n",
    "        def __init_(self):\n",
    "        # 何もしない\n",
    "            pass\n",
    "    \n",
    "        def W(self, n_nodes1, n_nodes2):\n",
    "            np.random.seed(1)\n",
    "            W = (1/np.sqrt(n_nodes1)) * np.random.randn(n_nodes1, n_nodes2)\n",
    "            return W\n",
    "        \n",
    "        def B(self, n_nodes1, n_nodes2):\n",
    "            np.random.seed(1)\n",
    "            b = (1/np.sqrt(n_nodes1)) * np.random.randn(n_nodes2)\n",
    "            return b\n",
    "    \n",
    "    class HeInitializer:\n",
    "        def __init_(self):\n",
    "            # 何もしない\n",
    "            pass\n",
    "\n",
    "        def W(self, n_nodes1, n_nodes2):\n",
    "            np.random.seed(1)\n",
    "            W = np.sqrt(2/n_nodes1) * np.random.randn(n_nodes1, n_nodes2)\n",
    "            return W\n",
    "\n",
    "        def B(self, n_nodes1, n_nodes2):\n",
    "            np.random.seed(1)\n",
    "            b = np.sqrt(2/n_nodes1) * np.random.randn(n_nodes2)\n",
    "            return b\n",
    "    \n",
    "    class SGD:\n",
    "        def __init__(self, lr=0.001):\n",
    "            self.lr = lr\n",
    "        def update(self, layer, dw, db):\n",
    "            layer.W = layer.W - self.lr*dw\n",
    "            layer.B = layer.B - self.lr*db\n",
    "            \n",
    "            return layer\n",
    "    \n",
    "    class AdaGrad:\n",
    "        def __init__(self, lr=0.001):\n",
    "            self.lr = lr\n",
    "            self.hw = None\n",
    "            self.hb = None\n",
    "\n",
    "        def update(self, layer, dw, db):\n",
    "            if (self.hw is None) or (self.hb is None):\n",
    "                self.hw = np.zeros_like(dw)\n",
    "                self.hb = np.zeros_like(db)\n",
    "\n",
    "            self.hw = self.hw + (dw*dw)\n",
    "            layer.W = layer.W - self.lr*dw/(np.sqrt(self.hw) + 1e-7)\n",
    "\n",
    "            self.hb = self.hb + (db*db)\n",
    "            layer.B = layer.B - self.lr*db/(np.sqrt(self.hb) + 1e-7)\n",
    "         \n",
    "            return layer\n",
    "    \n",
    "    class FC:\n",
    "        def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "            self.optimizer = optimizer\n",
    "            \n",
    "            self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "            self.B = initializer.B(n_nodes1, n_nodes2)\n",
    "            self.x = None\n",
    "            self.dw = None\n",
    "            self.db = None\n",
    "            \n",
    "        def forward(self, x):\n",
    "            self.x = x\n",
    "            return (np.dot(x, self.W) + self.B )\n",
    "\n",
    "        def backward(self, dout):\n",
    "            dw = np.dot((self.x).T, dout)\n",
    "            db = np.sum(dout, axis=0)\n",
    "            \n",
    "            # パラメータを更新\n",
    "            self = self.optimizer.update(self, dw, db)\n",
    "            \n",
    "            # 前の層に渡す\n",
    "            dZ = np.dot(dout, (self.W).T)\n",
    "            \n",
    "            return dZ\n",
    "        \n",
    "    class Convolution:\n",
    "        def __init__(self, w, b, optimizer, stride=1, pad=0):\n",
    "            self.optimizer = optimizer\n",
    "            \n",
    "            self.W = w\n",
    "            self.B = b\n",
    "            self.stride = stride\n",
    "            self.pad = pad\n",
    "\n",
    "            # 中間データ（backward時に使用）\n",
    "            self.x = None   \n",
    "            self.col = None\n",
    "            self.col_W = None\n",
    "\n",
    "            # 重み・バイアスパラメータの勾配\n",
    "            self.dW = None\n",
    "            self.db = None\n",
    "\n",
    "        def _N_out_h(self, H, FH):\n",
    "            # H:入力データの高さ、FH:フィルタの高さ\n",
    "            return (1 + int((H + 2*self.pad - FH) / self.stride))\n",
    "\n",
    "        def _N_out_w(self, W, FW):\n",
    "            # W:入力データの高さ、FW:フィルタの高さ\n",
    "            return (1 + int((W + 2*self.pad - FW) / self.stride))\n",
    "\n",
    "        def forward(self, x):\n",
    "            # xのIFを4次元に変更する\n",
    "            # x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
    "\n",
    "            N, C, H, W = x.shape # N:データ数, C:チャネル数、H:データの高さ、W:データの幅\n",
    "            FN, C, FH, FW = self.W.shape # FN:フィルタ数、C:チャネル数、FH:フィルタの高さ、FW:フィルタの幅\n",
    "            \n",
    "            # 一つあたりの出力データのサイズ(畳み込み後のサイズ)を求める\n",
    "            out_h = self._N_out_h(H, FH)\n",
    "            out_w = self._N_out_w(W, FW)\n",
    "            #print(\"出力データのサイズ\")\n",
    "            #print(out_h, out_w)\n",
    "\n",
    "            # 演算を行うため2次元のデータに変換する\n",
    "            col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "            col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "            # 畳み込み処理\n",
    "            out = np.dot(col, col_W) + self.B\n",
    "\n",
    "            # 畳み込み処理の結果を任意の次元に変換 C:チャンネル1の場合\n",
    "            out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "            # out = out.transpose(1, 0) \n",
    "\n",
    "            # backward処理のためにデータ保存\n",
    "            self.x = x\n",
    "            self.col = col\n",
    "            self.col_W = col_W\n",
    "\n",
    "            #print(\"Nanの確認\", np.sum(x), np.sum(col), np.sum(col_W))\n",
    "            \n",
    "            return out\n",
    "\n",
    "        def backward(self, dout):\n",
    "            FN, C, FH, FW = self.W.shape # FN:フィルタ数、C:チャネル数、FH:フィルタの高さ、FW:フィルタの幅\n",
    "\n",
    "            # C:チャンネル1の場合\n",
    "            dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "            #dout =  out.transpose(1, 0)\n",
    "\n",
    "            self.db = np.sum(dout, axis=0)\n",
    "            self.dW = np.dot(self.col.T, dout)\n",
    "            self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "            dcol = np.dot(dout, self.col_W.T)\n",
    "            dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "            # パラメータを更新\n",
    "            # print(\"self.dW, self.dbの確認:更新前\", np.sum(self.dW), np.sum(self.db))\n",
    "            self = self.optimizer.update(self, self.dW, self.db)\n",
    "            # print(\"self.dW, self.dbの確認:更新後\", np.sum(self.dW), np.sum(self.db))\n",
    "    \n",
    "            return dx\n",
    "    class Pooling:\n",
    "        def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "            self.pool_h = pool_h\n",
    "            self.pool_w = pool_w\n",
    "            self.stride = stride\n",
    "            self.pad = pad\n",
    "\n",
    "            self.x = None\n",
    "            self.arg_max = None\n",
    "\n",
    "        def forward(self, x):\n",
    "            # xのIFを4次元に変更する\n",
    "            # x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
    "            \n",
    "            N, C, H, W = x.shape\n",
    "            out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "            out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "            col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "            col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "            arg_max = np.argmax(col, axis=1)\n",
    "            out = np.max(col, axis=1)\n",
    "            out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "            self.x = x\n",
    "            self.arg_max = arg_max\n",
    "            \n",
    "            return out\n",
    "\n",
    "        def backward(self, dout):\n",
    "            dout = dout.transpose(0, 2, 3, 1)\n",
    "\n",
    "            pool_size = self.pool_h * self.pool_w\n",
    "            dmax = np.zeros((dout.size, pool_size))\n",
    "            dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "            dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "\n",
    "            dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "            dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "\n",
    "            return dx\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        # 検証データ(X_val, y_val)の有無を確認\n",
    "        flag_val = True\n",
    "        if (X_val is None) and (y_val is None):\n",
    "            # 検証データが入力されなかった場合、検証データの保存と学習過程を表示しない\n",
    "            flag_val = False\n",
    "\n",
    "        # self.sigma : ガウス分布の標準偏差\n",
    "        # self.lr : 学習率\n",
    "        # self.n_nodes1 : 1層目のノード数\n",
    "        # self.n_nodes2 : 2層目のノード数\n",
    "        # self.n_output : 出力層のノード数\n",
    "        sigma = self.sigma\n",
    "        alpha = self.lr\n",
    "        epoch = self.epoch\n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        # 初期化\n",
    "        score = np.zeros(epoch)\n",
    "        accuracy = np.zeros(epoch)\n",
    "        score_val = np.zeros(epoch)\n",
    "        accuracy_val = np.zeros(epoch)\n",
    "        \n",
    "        # ノード設定\n",
    "        # [Conv - ReLU - Pool]:4320 - 400:[afine - ReLU]:100 - 100:[afine - ReLU]:10 \n",
    "        filter_num = 30\n",
    "        filter_size = 5\n",
    "        filter_pad = 0\n",
    "        filter_stride = 1\n",
    "        hidden_size = 100\n",
    "        input_size = 28\n",
    "        output_size = 10\n",
    "        weight_init_std = sigma\n",
    "        \n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "        \n",
    "        # 畳み込み層　出力チャンネル数30、フィルタサイズ5×5、ストライド1\n",
    "        np.random.seed(1)\n",
    "        w_C1 = weight_init_std*np.random.randn(filter_num, 1, filter_size, filter_size)\n",
    "        b_C1 = np.zeros(filter_num)\n",
    "        \n",
    "        self.C1 = self.Convolution(w_C1, b_C1, self.AdaGrad(alpha), stride=1, pad=0)\n",
    "        self.activation1 = self.ReLU()\n",
    "        self.P1 = self.Pooling(pool_h=2, pool_w=2, stride=2, pad=0)\n",
    "        \n",
    "        \"\"\"\n",
    "        # ノード設定\n",
    "        #  # 784:[afine - ReLU]:400 - 400:[afine - ReLU]:100 - 100:[afine - ReLU]:10\n",
    "        self.FC1 = self.FC(self.n_features, self.n_nodes1, self.SimpleInitializer(sigma), self.SGD(alpha))\n",
    "        self.activation1 = self.ReLU()\n",
    "        \"\"\"\n",
    "        self.FC2 = self.FC(pool_output_size, self.n_nodes2, self.HeInitializer(), self.AdaGrad(alpha))\n",
    "        self.activation2 = self.ReLU()\n",
    "        \n",
    "        self.FC3 = self.FC(self.n_nodes2, self.n_output, self.HeInitializer(), self.AdaGrad(alpha))\n",
    "        self.activation3 = self.activation_softmax()\n",
    "        \n",
    "        for count_epoch in range(epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size, seed=count_epoch)\n",
    "            \n",
    "            # @@@debug\n",
    "            start = time.time()\n",
    "            count = 0\n",
    "            \n",
    "            # 1 epoch\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                count = count + 1\n",
    "                \n",
    "                mini_y_train_one_hot = self._encode_10(mini_y_train)\n",
    "                \n",
    "                # IFを合わせるため、chを追加\n",
    "                mini_X_train = mini_X_train.reshape(mini_X_train.shape[0], 1, mini_X_train.shape[1], mini_X_train.shape[2])\n",
    "                \n",
    "                # forward\n",
    "                C1 = self.C1.forward(mini_X_train) # 畳み込み層　出力チャンネル数6、フィルタサイズ5×5、ストライド1\n",
    "                C1_activation = self.activation1.forward(C1) # ReLu\n",
    "                P1 = self.P1.forward(C1_activation) # 最大プーリング\n",
    "                \n",
    "                # 4dを次の層に渡すため1次元に変換\n",
    "                P1_flatten = P1.reshape(-1, P1.shape[1]*P1.shape[2]*P1.shape[3])\n",
    "                \n",
    "                \"\"\"\n",
    "                A1 = self.FC1.forward(P1_flatten) \n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                \"\"\"\n",
    "\n",
    "                A2 = self.FC2.forward(P1_flatten)                \n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                \n",
    "                # back\n",
    "                dA3 = self.activation3.backward(Z3, mini_y_train_one_hot)\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "\n",
    "                # 平滑化したデータを4dに変換\n",
    "                dZ1_4d = dZ1.reshape(batch_size, P1.shape[1], P1.shape[2], P1.shape[3])\n",
    "                \n",
    "                dP1 = self.P1.backward(dZ1_4d)\n",
    "                dA1 = self.activation1.backward(dP1)\n",
    "                dZ0 = self.C1.backward(dA1)\n",
    "                \n",
    "                \"\"\"\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しないがw,bの更新で利用\n",
    "                \"\"\"\n",
    "                \n",
    "                # 1バッチあたりの損失\n",
    "                portion = Z3\n",
    "                label = np.argmax(portion, axis = 1)\n",
    "            \n",
    "                _d_score = self._calc_loss(self._encode_10(mini_y_train), portion)\n",
    "                _d_accuracy = accuracy_score(label, mini_y_train)\n",
    "            \n",
    "                if count % 1000 == 0:\n",
    "                    #print(\"epoch:\", count_epoch+1, \"count:\", count, _d_score, _d_accuracy)\n",
    "                    #break\n",
    "                    pass\n",
    "\n",
    "            # エポックごとの損失\n",
    "            y_pred, y_pred_portion = self.predict(X[0:10000])\n",
    "            \n",
    "            # 交差エントロピー誤差(1 epoch)\n",
    "            score[count_epoch] = self._calc_loss(self._encode_10(y[0:10000]), y_pred_portion)\n",
    "            \n",
    "            # 正解率\n",
    "            accuracy[count_epoch] = accuracy_score(y_pred, y[0:10000])\n",
    "            \n",
    "            if flag_val == True:\n",
    "                y_pred_val, y_pred_val_portion = self.predict(X_val[0:10000])\n",
    "                score_val[count_epoch] = self._calc_loss(self._encode_10(y_val[0:10000]), y_pred_val_portion)\n",
    "                accuracy_val[count_epoch] = accuracy_score(y_pred_val, y_val[0:10000])\n",
    "\n",
    "            if self.verbose:\n",
    "                #verboseをTrueにした際は学習過程などを出力する\n",
    "                # @@@debug\n",
    "                elapsed_time = time.time() - start\n",
    "                print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "                \n",
    "                if flag_val == True:\n",
    "                    print(\"epoch:\",(count_epoch+1),\"accuracy:\",accuracy[count_epoch], \"loss:\", score[count_epoch])\n",
    "                    print(\"epoch:\",(count_epoch+1),\"accuracy_val:\",accuracy_val[count_epoch], \"loss_val:\", score_val[count_epoch])\n",
    "                else:\n",
    "                    print(\"epoch:\",(count_epoch+1),\"accuracy:\",accuracy[count_epoch], \"loss:\", score[count_epoch])\n",
    "        \n",
    "            # 学習データの保存\n",
    "            self._score = score\n",
    "            self._accuracy = accuracy\n",
    "            self._score_val = score_val\n",
    "            self._accuracy_val = accuracy_val\n",
    "        \n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        X = X.reshape(X.shape[0], 1, X.shape[1], X.shape[2])\n",
    "        \n",
    "        C1 = self.C1.forward(X) # 畳み込み層　出力チャンネル数6、フィルタサイズ5×5、ストライド1\n",
    "        C1_activation = self.activation1.forward(C1) # ReLu\n",
    "        P1 = self.P1.forward(C1_activation) # 最大プーリング\n",
    "        \n",
    "        # 4dを次の層に渡すため1次元に変換\n",
    "        P1_flatten = P1.reshape(-1, P1.shape[1]*P1.shape[2]*P1.shape[3])        \n",
    "        \n",
    "        \"\"\"\n",
    "        A1 = self.FC1.forward(X) \n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        \"\"\"\n",
    "        \n",
    "        A2 = self.FC2.forward(P1_flatten)                \n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        \n",
    "        portion = Z3\n",
    "        label = np.argmax(portion, axis = 1)\n",
    "        \n",
    "        return label, portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:630.9281468391418[sec]\n",
      "epoch: 1 accuracy: 0.9161 loss: 0.2875303765609803\n",
      "epoch: 1 accuracy_val: 0.9116 loss_val: 0.2897560947954917\n",
      "CPU times: user 4min 13s, sys: 2min 50s, total: 7min 3s\n",
      "Wall time: 10min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_test = ScratchDeepNeuralNetrowkClassifier(epoch = 1, alpha = 0.005, activation='ReLU', optimizer=\"AdaGrad\", init=\"HeInitializer\", verbose = True)\n",
    "clf_test.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy（正解率） 0.9193\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_pred_portion = clf_test.predict(X_test)\n",
    "print(\"Accuracy（正解率）\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
